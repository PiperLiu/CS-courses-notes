# 数据库系统中的排序与聚合：应对内存限制的归并策略

<!-- @import "[TOC]" {cmd="toc" depthFrom=2 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [内存不足时的大数据排序：外部归并排序 (External Merge Sort)](#内存不足时的大数据排序外部归并排序-external-merge-sort)
- [聚合操作 (Aggregations)](#聚合操作-aggregations)
  - [基于排序的聚合 (Sorting Aggregation)](#基于排序的聚合-sorting-aggregation)
  - [基于哈希的聚合 (Hashing Aggregate)](#基于哈希的聚合-hashing-aggregate)

<!-- /code_chunk_output -->

在关系模型中，表中的元组本身并没有特定的顺序。然而，许多数据库查询操作，例如 `ORDER BY` 子句、`JOIN` 操作、`DISTINCT` 去重以及 `GROUP BY` 聚合，都需要对数据进行排序。此外，将已排序的元组批量加载到 B+Tree 索引中也更加高效。本课程的核心目标之一，便是探讨如何在数据量远超可用内存的情况下， **有效地排序和聚合大量数据，同时最大限度地减少磁盘 I/O 操作** 。

### 内存不足时的大数据排序：外部归并排序 (External Merge Sort)

当整个数据集无法完全加载到内存中时，传统的内存排序算法（如快速排序 QuickSort 或堆排序 HeapSort）会因频繁的随机磁盘 I/O 而变得极其低效。为此，数据库系统采用 **外部归并排序（External Merge Sort）** ，这是一种 **分而治之 (Divide-and-Conquer)** 的排序算法。

其基本思路分为两个阶段：

**第一阶段：排序 (Phase #1 – Sorting)**

* 系统会 **读取尽可能多的数据块（通常为 `B` 个页面，`B` 为可用缓冲区页数）到内存中** 。
* 在内存中对这些数据进行 **就地排序** ，形成一个个 **“运行” (runs)** 。
* 将这些已排序的运行 **写回磁盘** 。
* 这个过程会一直重复，直到所有原始数据都被分块排序并写回磁盘。

**第二阶段：合并 (Phase #2 – Merging)**

* 在后续的趟（pass）中，系统会 **将之前生成的多个小规模已排序运行合并成更大的已排序运行** 。
* 这个过程会 **反复进行** ，直到所有运行被合并成一个完整的、已排序的数据集。

为了提高合并效率，通常采用 **K 路归并 (K-way Merge)** 的方式，而非简单的 2 路归并。在 K 路归并中，系统会同时合并 `K` 个已排序的运行。对于外部归并排序，这意味着在合并阶段，数据库系统将 `B-1` 个缓冲区页用于输入，将 1 个缓冲区页用于输出。总的 I/O 成本通常为 `2N * (# passes)`，其中 `N` 是页数，`# passes` 的计算公式为 `1 + ⌈logB-1 ⌈N / B⌉ ⌉`。

**优化策略**

* **双重缓冲 (Double Buffering)** ：为了最大限度地提高顺序 I/O 的效率并减少等待时间，系统会 **预取 (Prefetch)** 后续需要处理的运行到后台的第二个缓冲区中。这意味着当 CPU 正在处理当前的数据时，异步 I/O 操作（通常由操作系统或专门的 I/O 调度线程处理）会同时从磁盘中读取下一批数据。这样就实现了 **CPU 计算和磁盘 I/O 的重叠执行** ，避免了两者之间的乒乓效应，从而提高了整体性能。

**利用 B+Tree 加速排序**

* 如果表上已经存在 B+Tree 索引，并且需要排序的键与索引键相同，那么可以利用 B+Tree 来加速排序操作。
* **聚簇 B+Tree (Clustered B+Tree)** ：如果 B+Tree 是聚簇索引（意味着数据元组的物理存储顺序与索引键的逻辑顺序一致），那么只需遍历 B+Tree 的叶子页面（这些页面本身就是按序排列的）即可直接获取已排序的数据。这种方式的效率极高，因为它 **不涉及额外的计算成本，且所有磁盘访问都是顺序的** 。
* **非聚簇 B+Tree (Unclustered B+Tree)** ：相比之下，如果 B+Tree 是非聚簇索引（即索引的排序顺序与数据元组的物理存储位置无关），那么利用它进行排序通常是一个 **非常糟糕的选择** 。因为对于每个记录，都需要追逐指针到其存储的数据页，这会导致大量的 **随机磁盘 I/O** ，性能会非常差。

### 聚合操作 (Aggregations)

聚合操作是将多个元组的值合并成一个单一的标量值，例如 `COUNT`、`SUM`、`AVG`、`MIN`、`MAX` 等。数据库系统通常有两种主要的实现方式： **基于排序的聚合** 和 **基于哈希的聚合** 。

#### 基于排序的聚合 (Sorting Aggregation)

**思路非常直接** ：首先根据 `GROUP BY` 的键对数据进行排序（如果数据量大，会使用外部归并排序）。

一旦数据排序完成，只需 **对已排序的数据进行一次顺序扫描 (Sequential Scan)** ，即可轻松地计算聚合结果或消除重复项（如 `DISTINCT`）。当扫描到同一键值的连续元组时，可以直接进行聚合计算。

**优点** ：如果查询结果本身就需要按聚合键排序，那么这种方法非常高效，因为排序一次满足了两个需求。

**缺点** ：如果查询结果不要求有序，那么排序过程本身的成本可能较高。

#### 基于哈希的聚合 (Hashing Aggregate)

**如果聚合查询结果不要求有序，哈希方法通常会更快** ，因为它在计算上可能比排序更便宜。

当所有数据都 **能放入内存时** ，系统会构建一个 **临时 (Ephemeral)** 的哈希表。扫描输入数据时，对于每个记录，检查哈希表中是否已存在对应条目：
* 对于 `DISTINCT` 操作，如果键已存在，则说明是重复项，直接丢弃。
* 对于 `GROUP BY` 操作，如果键已存在，则更新其对应的聚合值；否则，插入新条目。

**如果数据量太大，哈希表在内存中放不下** ，则需要使用 **外部哈希聚合 (External Hashing Aggregate)** ，它同样采用分而治之的策略来应对磁盘溢出。这个过程分为两个阶段：

**第一阶段：分区 (Phase #1 – Partition)**

* 使用第一个哈希函数 `h1` 将元组 **分割到磁盘上的不同分区（桶）中** 。
* **关键是哈希函数的确定性** ：具有相同键值的元组将始终落入同一个分区。
* 系统利用缓冲区管理器将这些分区的数据 **溢出到磁盘** 。通常，`B-1` 个缓冲区页用于不同的输出分区，1 个缓冲区页用于输入数据。

**第二阶段：重哈希 (Phase #2 – ReHash)**

* 对于磁盘上的每个分区，将其数据 **读入内存** 。
* 在内存中，使用 **第二个哈希函数 `h2` (与 `h1` 不同)** 再次构建一个哈希表。 **通过分区，保证处理每个小块时，同一个键值的所有元组都集中在该分区内** ，因此可以对该分区的所有数据进行聚合计算。
* 这个阶段 **假设每个分区都足够小，可以完全加载到内存中** 。
* 在重哈希阶段，哈希表会存储 `(GroupKey → RunningValue)` 形式的键值对。`RunningValue` 的内容取决于具体的聚合函数（例如，`AVG` 会维护 `(COUNT, SUM)`，`MIN` 维护 `(MIN)` 等）。当遇到一个元组时，如果 `GroupKey` 已存在，则更新 `RunningValue`；否则，插入新的键值对。

无论是排序还是哈希，这两种技术都体现了数据库系统设计中的一个核心理念： **将大的问题分解为小的、可管理的单元进行处理，并优先采用能够最大化顺序 I/O 的算法** 。这对于处理磁盘数据至关重要，因为顺序 I/O 远比随机 I/O 效率更高。
